/*
 * CDDL HEADER START
 *
 * The contents of this file are subject to the terms of the
 * Common Development and Distribution License, Version 1.0 only
 * (the "License").  You may not use this file except in compliance
 * with the License.
 *
 * You can obtain a copy of the license at http://smartos.org/CDDL
 *
 * See the License for the specific language governing permissions
 * and limitations under the License.
 *
 * When distributing Covered Code, include this CDDL HEADER in each
 * file.
 *
 * If applicable, add the following below this CDDL HEADER, with the
 * fields enclosed by brackets "[]" replaced with your own identifying
 * information: Portions Copyright [yyyy] [name of copyright owner]
 *
 * CDDL HEADER END
 *
 * Copyright (c) 2013, Joyent, Inc. All rights reserved.
 *
 */

var assert = require('assert');
var async = require('/usr/node/node_modules/async');
var EventEmitter = require('events').EventEmitter;
var spawn = require('child_process').spawn;
var utils = require('utils');

// utils
var trim = utils.trim;

// zfs_list_queue variables for the serialization of 'zfs list' calls
var zfs_list_in_progress = {};
var zfs_list_queue;

function cleanDatasetObject(obj)
{
    var number_fields = [
        'avail',
        'available',
        'copies',
        'creation',
        'filesystem_limit',
        'quota',
        'recsize',
        'recordsize',
        'refer',
        'referenced',
        'refquota',
        'refreserv',
        'refreservation',
        'reserv',
        'reservation',
        'snapshot_limit',
        'usedbychildren',
        'usedbydataset',
        'usedbyrefreservation',
        'usedbysnapshots',
        'used',
        'userrefs',
        'utf8only',
        'version',
        'volblock',
        'volblocksize',
        'volsize',
        'written'
    ];

    // We should always have mountpoint, dataset and type because we force them
    // to be included in zfsList()
    assert(obj.hasOwnProperty('mountpoint'), 'cleanDatasetObject('
        + JSON.stringify(obj) + '): missing mountpoint');
    assert(obj.hasOwnProperty('name'), 'cleanDatasetObject('
        + JSON.stringify(obj) + '): missing name');
    assert(obj.hasOwnProperty('type'), 'cleanDatasetObject('
        + JSON.stringify(obj) + '): missing type');

    // convert numeric fields to proper numbers
    number_fields.forEach(function (field) {
        if (obj.hasOwnProperty(field) && obj[field] !== '-') {
            obj[field] = Number(obj[field]);
        }
    });

    if (obj.type === 'volume') {
        obj.mountpoint = '/dev/zvol/rdsk/' + obj.name;
    } else if (obj.mountpoint === '-' || obj.mountpoint === 'legacy') {
        obj.mountpoint = '/' + obj.name;
    }
}

function addDatasetResult(fields, types, results, line, log)
{
    var dataset;
    var field;
    var lfields;
    var obj;
    var snapparts;
    var snapobj;

    line = trim(line);

    if (line.length === 0) {
        return;
    }

    lfields = line.split(/\s+/);

    if (lfields.length !== fields.length) {
        return;
    }

    obj = {};

    for (field in fields) {
        obj[fields[field]] = lfields[field];
    }

    cleanDatasetObject(obj);

    if (!results.hasOwnProperty('datasets')) {
        results.datasets = {};
    }
    if (!results.hasOwnProperty('mountpoints')) {
        results.mountpoints = {};
    }
    if (types.indexOf('snapshot') !== -1 && obj.type === 'snapshot') {
        if (!results.hasOwnProperty('snapshots')) {
            results.snapshots = {};
        }

        /*
         * For snapshots we store the snapname and optionally creation keyed by
         * dataset name So that we can include the list of snapshots for a
         * dataset on a VM.
         */
        snapparts = obj.name.split('@');
        assert.equal(snapparts.length, 2);
        dataset = snapparts[0];
        snapobj = {snapname: snapparts[1], dataset: dataset};
        if (!results.snapshots.hasOwnProperty(dataset)) {
            results.snapshots[dataset] = [];
        }
        if (obj.hasOwnProperty('creation')) {
            snapobj.created_at = obj.creation;
        }
        results.snapshots[dataset].push(snapobj);
    }

    results.datasets[obj.name] = obj;

    /*
     * snapshots don't have mountpoint that we care about and we don't count
     * 'none' as a mountpoint. If we otherwise have a mountpoint that looks like
     * a path, we add a pointer from that to the dataset name.
     */
    if (obj.type !== 'snapshot' && obj.mountpoint[0] === '/') {
        /*
         * For zoned filesystems (delegated datasets) we don't use mountpoint as
         * this can be changed from within the zone and is therefore not
         * reliable. Also, when a delegated dataset is assigned but the zone's
         * not been booted, the delegated dataset will not have the 'zoned'
         * property.  So we also check if the name ends in /data.
         */
        if (obj.hasOwnProperty('zoned') && obj.zoned === 'on') {
            // don't add zoned datasets to mountpoints
            /*jsl:pass*/
        } else if (obj.name.split('/')[2] === 'data') {
            // name is /data, skip
            /*jsl:pass*/
        } else {
            // here we have what looks like a normal non-zoned dataset that's
            // probably a zoneroot, add to mountpoints mapping.
            results.mountpoints[obj.mountpoint] = obj.name;
        }
    }
}

/*
 * Arguments:
 *
 * 'fields'   - should be an array of fields as listed in the zfs(1m) man page.
 * 'types'    - should be one or more of: filesystem, snapshot, volume.
 * 'log'      - should be a bunyan logger object.
 * 'callback' - will be called with (err, results)
 *
 * On failure: callback's err will be an Error object, ignore results.
 * On success: callback's results is an object with one or more members of:
 *
 *     results.datasets
 *
 *         keyed by dataset name containing the values for the requested fields.
 *
 *         Eg: results.datasets['zones/cores'] === { name: 'zones/cores', ... }
 *
 *     results.mountpoints
 *
 *         keyed by mountpoint with value being dataset name.
 *
 *         Eg: results.mountpoints['/zones/cores'] === 'zones/cores'
 *
 *     results.snapshots
 *
 *         keyed by dataset with value being array of snapname and created_at.
 *
 *         Eg: results.snapshots['/zones/cores'] === ['snap1', ...]
 *
 * For non-zoned filesystem datasets (these should be the zoneroot datasets),
 * you can use mountpoint which comes from zoneadm's "cheap" info and use that
 * to get to the dataset and from datasets[dataset] get the info.
 *
 * For volumes (KVM VM's disks) you can also use mountpoint as we'll set that
 * to the block device path and that's available from the devices section of
 * the zoneconfig.
 *
 * For zoned filesystems (delegated datasets) use the dataset name, as the
 * mountpoint can be changed from within the zone.
 *
 */
function zfsList(fields, types, log, callback) {
    var args;
    var buffer = '';
    var lines;
    var line_count = 0;
    var cmd = '/usr/sbin/zfs';
    var req_fields = ['mountpoint', 'name', 'type'];
    var results = {};
    var zfs_child;

    assert(Array.isArray(types));
    assert(Array.isArray(fields));
    assert(log, 'no logger passed to zfsList()');

    // add any missing required fields
    req_fields.forEach(function (field) {
        if (fields.indexOf(field) === -1) {
            fields.push(field);
        }
    });

    args = ['list', '-H', '-p', '-t', types.join(','), '-o', fields.join(',')];

    log.debug({cmdline: cmd + ' ' + args.join(' ')}, 'executing zfs');
    zfs_child = spawn(cmd, args, {stdio: 'pipe'});
    log.debug('zfs[' + zfs_child.pid + '] running');

    zfs_child.stdout.on('data', function (data) {
        var line;

        buffer += data.toString();
        lines = buffer.split('\n');
        while (lines.length > 1) {
            line = lines.shift();
            line_count++;

            // Add this line to results
            addDatasetResult(fields, types, results, line, log);
        }
        buffer = lines.pop();
    });

    // doesn't take input.
    zfs_child.stdin.end();

    zfs_child.on('exit', function (code) {

        log.debug('zfs[' + zfs_child.pid + '] exited with code: ' + code
            + ' (' + line_count + ' lines to stdout)');
        if (code === 0) {
            callback(null, results);
        } else {
            callback(new Error('zfs exited prematurely with code: ' + code));
        }
    });
}

/*
 * This queue is used to handle zfs list requests. We do this because of OS-1834
 * in order to only run one 'zfs list' at a time. If we need to get data from
 * 'zfs list', the parameters we want to list are pushed onto this queue. If a
 * list is already running with the same parameters, we'll return the output
 * from that one when it completes to all the consumers. If there's not one
 * running, or the parameters are different, this set of parameters will be
 * pushed onto the tail of the queue. The queue is processed serially so long
 * as there are active requests.
 */
zfs_list_queue = async.queue(function (task, callback) {

    var fields = task.fields;
    var log = task.log;
    var started = Date.now(0);
    var types = task.types;

    zfsList(fields, types, log, function (err, data) {
        var emitter = zfs_list_in_progress[task];

        delete zfs_list_in_progress[task];
        emitter.emit('result', err, data);
        emitter.removeAllListeners('result');

        log.debug('zfs list took ' + (Date.now(0) - started) + ' ms');
        callback();
    });

}, 1);

zfs_list_queue.drain = function () {
    // XXX We use the global log here because this queue is not tied to one action.
    // log.trace('zfs_list_queue is empty');
};

function getZfsList(fields, types, log, callback) {
    var sorted_fields;
    var sorted_types;
    var task;

    sorted_fields = fields.slice().sort();
    sorted_types = types.slice().sort();

    task = {types: sorted_types, fields: sorted_fields, log: log};

    try {
        zfs_list_in_progress[task].on('result', callback);
    } catch (e) {
        if ((e instanceof TypeError)
            && (!zfs_list_in_progress.hasOwnProperty(task)
            || !zfs_list_in_progress[task].hasOwnProperty('on'))) {

            zfs_list_in_progress[task] = new EventEmitter();
            zfs_list_in_progress[task].on('result', callback);
            zfs_list_in_progress[task].setMaxListeners(0);
            zfs_list_queue.push(task);

            // callback() will get called when 'result' is emitted.
        } else {
            callback(e);
        }
    }
}

function getDatasets(options, callback)
{
    var fields;
    var log;
    var zfs_fields = [];
    var zfs_types = [];

    fields = options.fields;
    log = options.log;
    assert(log, 'no logger passed to getDatasets()');

    function addField(name) {
        if (zfs_fields.indexOf(name) === -1) {
            zfs_fields.push(name);
        }
    }

    function addType(name) {
        if (zfs_types.indexOf(name) === -1) {
            zfs_types.push(name);
        }
    }

    if (!fields || fields.length < 1) {
        // Default to grabbing everything we might possibly need.
        zfs_fields =  ['name', 'quota', 'volsize', 'mountpoint', 'type',
            'compression', 'recsize', 'volblocksize', 'zoned', 'creation',
            'refreservation'];
        zfs_types = ['filesystem', 'snapshot', 'volume'];
    } else {
        if (fields.indexOf('disks') !== -1) {
            addField('compression');
            addField('volsize');
            addField('volblocksize');
            addField('refreservation');
            addType('volume');
        }
        if (fields.indexOf('snapshots') !== -1) {
            addField('creation');
            addType('snapshot');
            addType('filesystem');
            addType('volume');
        }
        if (fields.indexOf('create_timestamp') !== -1) {
            // We might fall back to creation on the dataset for
            // create_timestamp if we have no create-timestamp attr.
            addField('creation');
            addType('filesystem');
        }
        if ((fields.indexOf('zfs_root_compression') !== -1)
            || (fields.indexOf('zfs_data_compression') !== -1)) {

            addField('compression');
            addType('filesystem');
        }
        if ((fields.indexOf('zfs_root_recsize') !== -1)
            || (fields.indexOf('zfs_data_recsize') !== -1)) {

            addField('recsize');
            addType('filesystem');
        }
        if (fields.indexOf('quota') !== -1) {
            addField('quota');
            addType('filesystem');
        }
        // both zpool and zfs_filesystem come from 'name'
        if (fields.indexOf('zpool') !== -1
            || fields.indexOf('zfs_filesystem') !== -1) {

            addField('name');
            addType('filesystem');
        }
        if (zfs_fields.length > 0) {
            // we have some fields so we need to zfs, make sure we have name,
            // mountpoint and type which we always need if we get anything.
            addField('name');
            addField('mountpoint');
            addField('type');

            if (zfs_types.indexOf('filesystem') !== -1) {
                // to differentiate between delegated and root filesystems
                addField('zoned');
            }
        } else {
            log.debug('no need to call zfs');
            callback(null, {
                datasets: {},
                mountpoints: {},
                snapshots: {}
            });
            return;
        }
    }

    /*
     * NOTE:
     * in the future, the plan is to have the list of types and fields
     * be dynamic based what's actually needed to handle the request.
     */

    getZfsList(zfs_fields, zfs_types, log, callback);
}

module.exports = {
    getDatasets: getDatasets
};
